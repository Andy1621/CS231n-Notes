# CS231n

### 课程资源

- 原课程：<http://cs231n.stanford.edu/>

- AI研习社视频：<https://ai.yanxishe.com/page/groupDetail/19>
- 官网笔记：<http://cs231n.github.io/>
- 知乎翻译笔记：<https://zhuanlan.zhihu.com/p/21930884>
- 作业代码：<https://github.com/lightaime/cs231n>、<https://github.com/Halfish/cs231n>

**Try your best and let it be!**

## 课程笔记

### Leture1

1. 计算机视觉顾名思义就是针对视觉数据的研究

2. 视觉数据成为网络传输数据的主要部分

3. 跨学科

   ![](./pic/1.jpg)

4. 视觉处理源自视觉世界的简单结构——面向边缘

5. 从图像中构造出视觉世界中最终全面的3D表现

   ![](./pic/2.jpg)

6. 广义结构体、图形结构：将物体复杂结构简化成一个有更简单形状和几何结构的几何体

7. 目标识别=>目标分割

8. 目标识别的首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配，这比直接匹配整个目标要容易得多

9. 方向梯度直方图、可变部件模型

10. 在21世纪早期才开始真正拥有标注的数据集=>目标识别成为非常基本的问题

11. 2012年卷积神经网络的使用使ImageNet比赛误差率大大降低

12. CS231n 关注目标识别——图像分类问题，其他相关问题如目标检测或图像摘要生成

13. 2012AlexNet，2014GoogleNet、VGG，2015ResNet

14. 卷积90s提出，但直到2012才迅速发展，与计算能力的增长（摩尔定律、GPU并行运算）以及大规模高质量的数据集离不开

### Leture2

1. 图片分类，挑战：语义鸿沟、视角、光照、变形、遮挡、背景、类内误差

2. L1曼哈顿距离，坐标差值的绝对值之和，决定于坐标系的选择

   L2欧氏距离，坐标差值平方和开方，不关心坐标系的选择

   K近邻算法：选取最近的K个投票决定类型，关键是确定距离的计算公式

3. 将数据分为训练集、验证集和测试集

   交叉验证集，将数据分为训练集和测试集，训练集中轮流选一部分作为验证集（一般分为3、5、10份）

4. K近邻在图像任务中永远不会用到，L1、L2距离并不能很好地反映图像特征

5. **线性分类器** 
   $$
   f=(x_i, W, b)=Wx_i+b
   $$
   在$$x_i$$中加一个维度，值为常量1，即可将偏差和权重合并

6. 图像预处理经常需要**零均值中心化**，即减去平均值除以分布区间得到$$[-1,1]$$分布

7. **多类支持向量机损失**
   $$
   L_i = \sum_{j\neq y_i}max(0, s_j-s_{y_i}+\Delta)
   $$
   $$max(0,-)​$$常被称为折叶损失**hinge loss**，

   平方折叶损失SVM（L2-SVM）为$$max(0, -)^2$$

   平方折叶损失将更强烈地惩罚过界的边界值，不使用平方是更标准的版本，但在某些数据集中，平方折叶损失会工作得更好，可以通过交叉验证来决定到底使用哪个

   ![](./pic/3.jpg)

   多类SVM的目标是正确类别的分类比其他不正确类别的分类的分数要高，而且至少高出$$\Delta$$的边界值，如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。

8. **正则化惩罚**（常用L2范式）
   $$
   R(W) = \sum_k\sum_lW^2_{k, l}
   $$
   引入正则化项可以对大数值权重进行惩罚，提高其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响。L2惩罚倾向于更小更分散的权重向量，这就会鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。在后面的课程中可以看到，这一效果将会提升分类器的泛化能力，并避免**过拟合**。

9. 完整多类SVM损失函数
   $$
    L= \frac{1}{N}\sum_iL_i + \lambda R(W)
   $$

10. **Softmax分类器**
    **交叉熵损失**
    $$
    L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})
    $$
    在计算时中间项可能数值非常大，通常可在分子分母同乘以常数$$C, logC=-max_jf_j$$，就是将向量$$f$$中的数值进行平移，使得最大值为0
    $$
    \frac{e^{f_{y_i}}}{\sum_je^{f_j}}=\frac{Ce^{f_{y_i}}}{C\sum_je^{f_j}}=\frac{e^{f_{y_i}+logC}}{\sum_je^{f_j}+logC}
    $$

11. 通常来说两种分类器的表现差别很小，相对于Softmax分类器，SVM更加**”局部目标化“**，如第一个分类是正确的，$$[10, -100, -100]​$$或者$$[10, 9, 9]​$$对SVM来说没有不同。

    但对于Softmax分类器，前者的损失值远高于后者，换言之Softmax分类器对于分数是永远不会满意的：**正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小**。但SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。这可以被看做是SVM的一种特性。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。

### Leture 3

1. 损失函数最优化：随机搜索（随机枚举点，立刻更新权值），随机本地搜索（随机枚举点，损失变小才更新权值），跟随梯度（在梯度负方向更新）

2. 梯度计算：数值梯度法、分析梯度法

   - 数值梯度法：利用有限差值计算梯度
     $$
     grad=\frac{f(x+h)-f(x)}{h}
     $$
     中心差值公式效果更好
     $$
     grad=\frac{f(x+h)-f(x-h)}{2h}
     $$

   - 分析梯度法：利用微分公式求梯度

     在实际操作时为避免出错，常常将分析梯度法的结果与数值梯度法的结果作比较，以此检查实现的准确性

3. 小批量梯度下降：计算训练集中的小批量对权值进行更新

   当每个批量只有1个数据样本时，这种策略被称为随机梯度下降

4. 反向传播：利用链式法则递归计算表达式梯度

   比较难的是向量法操作计算维度，有个技巧是根据维度判断，无须记忆

### Leture 4

1. 全连接神经元参数爆炸

2. 卷积神经网络

   - 卷积层

     - 滤波器 filter
     - 感受野 receptive field
     - 深度
     - 步长 stride
     - 零填充 zero-padding

     卷积输出尺寸为（$W$为输入数据体尺寸，$F$为感受野尺寸，$P$为零填充数量，$S$为步长）
     $$
     W_2=（W_1-F+2P)/S+1
     $$

     $$
     H_2=（H_1-F+2P)/S+1
     $$
   参数数量为$F*F*D*K+K$，$K为滤波器数量$


     参数共享，深度切片 depth slice

   - 汇聚（Polling）层

     通常采用$2*2$滤波器，取最大值，计算与上述类似（没有零填充）

     未来可能很少甚至不使用汇聚层，可能使用较大的步长的卷积层代替

   - 全连接层

     与卷积层互化

   - ReLU层

3. 常见的卷积网络结构

   ![](./pic/4.jpg)

4. 几个小滤波器卷积层的组合比一个大滤波器卷积层好

5. 层的尺寸设置规律

   ![](./pic/5.jpg)

6. 在实际应用中，更小的步长效果更好。步长为1可以让空间维度的降采样全部由汇聚层负责，卷积层只负责对输入数据体的深度进行变换


### Leture 5

1. 单个神经元作为线性分类器，在输出端设置何时的损失函数

   设置sigmoid函数得二分类Softmax分类器，设置最大边界折叶损失函数得二分类SVM分类器

   正则化所有权重逐渐向零变化，从生物学角度可以看做逐渐遗忘

2. **常用激活函数**

   - **Sigmoid**
     $$
     \sigma (x)=\frac{1}{1+e^{-x}}
     $$
     ![](./pic/6.jpg)

     将输入值压缩到$[0, 1]$，将很大的负数变成0，很大的正数变成1，历史上非常常用，这是因为它对于神经元的激活频率有良好的解释：从完全不激活（0）到在求和后的最大频率处的完全饱和**saturated**的激活（1），现在不常用主要是因为以下**缺点**

     - **Sigmoid函数饱和使梯度消失**。sigmoid神经元有一个不好的特性，就是当神经元的激活在接近0或1处时会饱和：在这些区域，梯度几乎为0。回忆一下，在反向传播的时候，这个（局部）梯度将会与整个损失函数关于该门单元输出的梯度相乘。因此，如果局部梯度非常小，那么相乘的结果也会接近零，这会有效地“杀死”梯度，几乎就有没有信号通过神经元传到权重再到数据了。还有，为了防止饱和，必须对于权重矩阵初始化特别留意。比如，如果初始化权重过大，那么大多数神经元将会饱和，导致网络就几乎不学习了。

     - **Sigmoid函数的输出不是零中心的**。这个性质并不是我们想要的，因为在神经网络后面层中的神经元得到的数据将不是零中心的。这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数（比如在$f=w^Tx+b$中每个元素都$x>0$)，那么关于$w$的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数（具体依整个表达式$f$而定）。这将会导致梯度下降权重更新时出现$Z$字型的下降。然而，可以看到整个批量的数据的梯度被加起来后，对于权重的最终更新将会有不同的正负，这样就从一定程度上减轻了这个问题。因此，该问题相对于上面的神经元饱和问题来说只是个小麻烦，没有那么严重。

       ![](./pic/7.jpg)

       注意理解神经网络是有很多隐藏层的，多个隐藏层都用sigmoid时就会出现隐藏层输出都为正数，在反向传播时就会出现恒正或恒负的情况，就上图的二维梯度下降而言，梯度只能在第一和第三象限的方向减少，收敛极慢

   - **Tanh**
     $$
     tanh(x)=2\sigma (2x)-1
     $$
     ![](./pic/8.jpg)

     将实数值压缩到$[-1, 1]$中，同样也**存在饱和问题**，但不同的是**输出是零中心的**，因此在实际操作中比sigmoid函数更受欢迎

   - **ReLU**
     $$
     f(x)=max(0, x)
     $$
     ![](./pic/9.jpg)

     激活函数是一个关于0的阈值

     **优点**是相较于sigmoid和tanh函数，ReLU对于随机梯度的下降的收敛有巨大的加速作用，某论文实验中有6倍之多，据称是由于它的线性、非饱和的公式导致的

     **缺点**是在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低

   - **Leaky ReLU**
     $$
     f(x)=\alpha x,(x<0)，\alpha是一个小的常量\\
     f(x)=x,(x>=0)
     $$
     ![](./pic/11.jpg)

     除了有ReLU的优点外，还不会死掉

   - **ELU**
     $$
     f(x)=\alpha (e^x-1), (x <= 0)\\
     f(x)=x, (x > 0)
     $$
     ReLU的所有优点，与Leaky ReLU相比负向饱和状态增加了对噪声的鲁棒性，但指数计算量大

   - **Maxout**
     $$
     f(x)=max(w^T_1x+b_1, w^T_2x+b_2)
     $$
     ReLU和Leaky ReLU都是这个公式的特殊情况，拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。

   **一般来说，用ReLU非线性函数，注意设置好学习**率，监控网络中死亡神经元的比率。如果担心单元死亡问题，就试试Leaky ReLU或者Maxout，不要用sigmoid了。也可以试试tanh，但是其效果应该不如ReLU或者Maxout

3. 给出任意连续的函数$f(x)$和任意$\varepsilon > 0$，均存在一个至少含1个隐层的神经网络$g(x)$（并且网络中有合理选择的非线性激活函数，比如sigmoid），对于$\forall x$，使得$|f(x)-g(x)| < \varepsilon$，换句话说**神经网络可以近似任何连续函数**

   虽然一个2层网络在数学理论上能完美地近似所有连续函数，但在实际操作中效果相对较差，虽然在**理论上深层网络（使用了多个隐层）和单层网络的表达能力是一样的**，但是就实践经验而言，深度网络效果比单层网络好。在实践中3层的神经网络会比2层的表现好，然而继续加深（做到4，5，6层）很少有太大帮助。**卷积神经网络的情况却不同**，在卷积神经网络中，对于一个良好的识别系统来说，深度是一个极端重要的因素（比如数十(以10为量级)个可学习的层）。对于该现象的一种解释观点是：因为图像拥有层次化结构（比如脸是由眼睛等组成，眼睛又是由边缘组成），所以多层处理对于这种数据就有直观意义。

4. **用正则化、dropout和输入噪声等来控制过拟合比减少神经元数目要好得多**。不要减少网络神经元数目的主要原因在于**小网络更难使用梯度下降等局部方法来进行训练**：虽然小型网络的损失函数的局部极小值更少，也比较容易收敛到这些局部极小值，但是这些最小值一般都很差，损失值很高。相反，大网络拥有更多的局部极小值，但就实际损失值来看，这些局部极小值表现更好，损失更小

5. PCA：对数据零中心化处理，然后计算协方差矩阵，进行奇异值分解，得到矩阵$U$中为按特征值大小排序的特征向量，取前几项点乘即可降维**（PCA后数据变成零中心）**

6. 白化：归一化处理（没看懂）

7. 实际上在卷积神经网络中并不会采用PCA和白化，然而对数据进行零中心化操作还是非常必要的，对每个像素进行归一化也很常见

8. 何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。**应该怎么做呢？应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值**

9. **权重初始化**

   - **错误的**全零初始化

     如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。换句话说，如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头

   - 小随机数初始化

     权重初始值要非常接近0又不能等于0。解决方法就是将权重初始化为很小的数值，以此来*打破对称性*。其思路是：如果神经元刚开始的时候是随机且不相等的，那么它们将计算出不同的更新，并将自身变成整个网络的不同部分
     $$
     W=0.01*np.random.randn(D, H),\\randn函数是基于零均值和标准差的一个高斯分布
     $$

   - 使用$\frac{1}{sqrt(n)}​$校准方差

     随着输入数据量的增长，随机初始化的神经元的输出数据的分布中的方差也在增大。我们可以除以输入数据量的平方根来调整其数值范围，这样神经元输出的方差就归一化到1了。也就是说，建议将神经元的权重向量初始化为
     $$
     W=0.01*np.random.randn(D, H)/sqrt(n)
     $$

     没看懂证明	

   - 稀疏初始化

     一个处理非标定方差的方法是将所有权重矩阵设为0，但是为了打破对称性，每个神经元都**同下一层固定数目的神经元随机连接**（其权重数值由一个小的高斯分布生成），一个比较典型的连接数目是10个				

   - 偏置初始化

     **通常将偏置初始化为0**，这是因为随机小数值权重矩阵已经打破了对称性。对于ReLU非线性激活函数，有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值，这是因为他们认为这样做能让所有的ReLU单元一开始就激活，这样就能保存并传播一些梯度。然而，这样做是不是总是能提高算法性能并不清楚（有时候实验结果反而显示性能更差），所以通常还是使用0来初始化偏置参数

   实践中使用ReLU函数，并使用$W=np.random.randn(D, H)*sqrt(2.0/n)​$来进行权重初始化

10. **批量归一化**

    [批量归一化](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.03167)是loffe和Szegedy最近才提出的方法，该方法减轻了如何合理初始化神经网络这个棘手问题带来的头痛：），其做法是让激活数据在训练开始前通过一个网络，网络处理数据使其服从标准高斯分布。因为归一化是一个简单可求导的操作，所以上述思路是可行的。在实现层面，应用这个技巧通常意味着全连接层（或者是卷积层，后续会讲）与激活函数之间添加一个BatchNorm层。对于这个技巧本节不会展开讲，因为上面的参考文献中已经讲得很清楚了，需要知道的是在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。搞定

    归一化后对轻微扰动不敏感，学习更加容易

11. **梯度下降**

    - 随机梯度下降**SGD**：随机挑选小批量样例对权值进行更新，可能导致Z字形收敛（收敛过慢）、陷入鞍点（导数为0）
      $$
      x_{t+1} = x_t - \alpha \nabla f(x_t)
      $$

      ```python
      while True:
          dx = compute_gradient(x)
          x += learning_rate * dx
      ```

    - **SGD + 动量项momentum**：相当于加速度，沿着原本下降的方向继续前进，越过鞍点，初速度一般初始化为0
      $$
      v_{t+1} = \rho v_t + \nabla f(x_t)\\
      x_{t+1} = x_t - \alpha v_{t+1}
      $$

      ```python
      vx = 0
      while True:
          dx = compute_gradient(x)
          vx = rho * vx + dx
          x += learning_rate * vx
      ```

    - **Nesterov Momentum**：在加上加速度的点上取梯度，回到初始点进行更新
      $$
      v_{t+1} = \rho v_t - \alpha \nabla f(x_t + \rho v_t)\\
      x_{t+1} = x_t + v_{t+1}
      $$
      原式子不便于同时计算损失值和梯度，换元如下
      $$
      \widetilde {x_t} = x_t + \rho v_t\\
      v_{t+1} = \rho v_t + \nabla f(\widetilde {x_t})\\
      \widetilde {x_{t+1}} = \widetilde {x_t} - \rho v_t + (1 + \rho) v_{t+1}\\
      = \widetilde {x_t} + v_{t+1} + \rho (v_{t+1} - v_t)
      $$

      ```python
      v = 0
      while True:
          dx = compute_gradient(x)
          old_v = v
          v = rho * v - learning_rate * dx
          x += -rho * old_v + (1 + rho) * v
      ```

    - **AdaGrad**：梯度除以梯度平方和开方项，适当解决了不同方向梯度变化情况不同的问题（步长很好），对凸函数效果很好，但对非凸函数效果并不好，通常不用

      ```python
      grad_squared = 0
      while True:
          dx = compute_gradient(x)
          grad_squared += dx * dx
          x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)
      ```

    - **RMSProp**：AdaGrad的优化，乘以衰减率，可以很好地选择步长，并且避免了后续步长过小无法更新的问题

      ```python
      grad_squared = 0
      while True:
          dx = compute_gradient(x)
          grad_squared = decay_rate * grad_squared + (1 - decay_rate) dx * dx
          x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)
      ```

    - **Adam(almost)**：兼顾上述两类算法有点

      ```python
      first_moment = 0
      second_moment = 0
      while True:
          dx = compute_gradient(x)
          first_moment = beta1 * first_moment * (1 - beta1) * dx
          second_moment = beta2 * second_moment + (1 - beta2) * dx * dx
          x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)
      ```

      在第一步时，由于第二动量初始化为0，衰减率非常接近1，name求出第二动量项将是一个非常小的数，x会得到一个非常大的步长（第一第二动量项并不总会抵消）

    - **Adam(full form)**

      ```python
      first_moment = 0
      second_moment = 0
      while True:
          dx = compute_gradient(x)
          first_moment = beta1 * first_moment * (1 - beta1) * dx
          second_moment = beta2 * second_moment + (1 - beta2) * dx * dx
          first_unbias = first_moment / (1 - beta1 ** t)
          second_unbias = second_moment / (1 - beta2 ** t)
          x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)
      ```

      **默认用来解决任何问题，如下配置对大多模型起始都好**

      ```python
      beta1 = 0.9
      beta2 = 0.999
      learning_rate = 1e-3 or 5e-4
      ```

12. 学习率衰减

    带动量的SGD学习率衰减很常用，但是像Adam的优化算法很少用

    - **step decay**：每几个epoch学习率减半
    - **exponential decay**：$\alpha = \alpha _0e^{-kt}$
    - **1/t decay**：$\alpha = \alpha _0 / (1 + kt)$

    学习率衰减是一个二阶超参数，不在模型开始就决定如何衰减，而是先不采用衰减，观察损失函数，判断何处希望衰减

13. 前面的优化都是一阶逼近，可使用二阶逼近，牛顿法不需要指定学习率，但海森矩阵的逆运算计算量大，可使用拟牛顿法逼近这个逆，**L-BFGS**为二阶逼近，但在神经网络训练者少用
14. 模型集成：训练多个独立模型，在测试时取平均结果，通常能提升2%

15. 正则化

    - **Dropout**：在网络每次前向传播，随机将部分神经元激活函数结果置零，一般取0.5的概率，在全连接层中常见，在卷积层中也会使用，但并不是将神经元激活函数结果置零，而是随机将某几个通道置零（某些特征），需要使用更长时间训练

      **预测测试集时，简单地用dropout的概率乘以输出**

    - **Batch normalization**与deopout有类似效果，更常用
    - **Data Augmentation**：垂直、水平翻转，随机裁剪、放缩，色彩变换等等
    - **DropConnect**：随机将某些权重置零

16. 迁移学习

    固定底层参数，修改顶层权值（通常修改最后一层全连接层）

    ![](./pic/13.jpg)

    

