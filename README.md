# CS231n

### 课程资源

- 原课程：<http://cs231n.stanford.edu/>

- AI研习社视频：<https://ai.yanxishe.com/page/groupDetail/19>
- 官网笔记：<http://cs231n.github.io/>
- 知乎翻译笔记：<https://zhuanlan.zhihu.com/p/21930884>
- 作业代码：<https://github.com/lightaime/cs231n>、<https://github.com/Halfish/cs231n>

**Try your best and let it be!**

## 课程笔记

### Study1

1. 计算机视觉顾名思义就是针对视觉数据的研究

2. 视觉数据成为网络传输数据的主要部分

3. 跨学科

   ![](./pic/1.jpg)

4. 视觉处理源自视觉世界的简单结构——面向边缘

5. 从图像中构造出视觉世界中最终全面的3D表现

   ![](./pic/2.jpg)

6. 广义结构体、图形结构：将物体复杂结构简化成一个有更简单形状和几何结构的几何体

7. 目标识别=>目标分割

8. 目标识别的首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配，这比直接匹配整个目标要容易得多

9. 方向梯度直方图、可变部件模型

10. 在21世纪早期才开始真正拥有标注的数据集=>目标识别成为非常基本的问题

11. 2012年卷积神经网络的使用使ImageNet比赛误差率大大降低

12. CS231n 关注目标识别——图像分类问题，其他相关问题如目标检测或图像摘要生成

13. 2012AlexNet，2014GoogleNet、VGG，2015ResNet

14. 卷积90s提出，但直到2012才迅速发展，与计算能力的增长（摩尔定律、GPU并行运算）以及大规模高质量的数据集离不开

### Study2

1. 图片分类，挑战：语义鸿沟、视角、光照、变形、遮挡、背景、类内误差

2. L1曼哈顿距离，坐标差值的绝对值之和，决定于坐标系的选择

   L2欧氏距离，坐标差值平方和开方，不关心坐标系的选择

   K近邻算法：选取最近的K个投票决定类型，关键是确定距离的计算公式

3. 将数据分为训练集、验证集和测试集

   交叉验证集，将数据分为训练集和测试集，训练集中轮流选一部分作为验证集（一般分为3、5、10份）

4. K近邻在图像任务中永远不会用到，L1、L2距离并不能很好地反映图像特征

5. **线性分类器** 
   $$
   f=(x_i, W, b)=Wx_i+b
   $$
   在$$x_i$$中加一个维度，值为常量1，即可将偏差和权重合并

6. 图像预处理经常需要**零均值中心化**，即减去平均值除以分布区间得到$$[-1,1]$$分布

7. **多类支持向量机损失**
   $$
   L_i = \sum_{j\neq y_i}max(0, s_j-s_{y_i}+\Delta)
   $$
   $$max(0,-)​$$常被称为折叶损失**hinge loss**，

   平方折叶损失SVM（L2-SVM）为$$max(0, -)^2$$

   平方折叶损失将更强烈地惩罚过界的边界值，不使用平方是更标准的版本，但在某些数据集中，平方折叶损失会工作得更好，可以通过交叉验证来决定到底使用哪个

   ![](./pic/3.jpg)

   多类SVM的目标是正确类别的分类比其他不正确类别的分类的分数要高，而且至少高出$$\Delta$$的边界值，如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。

8. **正则化惩罚**（常用L2范式）
   $$
   R(W) = \sum_k\sum_lW^2_{k, l}
   $$
   引入正则化项可以对大数值权重进行惩罚，提高其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响。L2惩罚倾向于更小更分散的权重向量，这就会鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。在后面的课程中可以看到，这一效果将会提升分类器的泛化能力，并避免**过拟合**。

9. 完整多类SVM损失函数
   $$
    L= \frac{1}{N}\sum_iL_i + \lambda R(W)
   $$

10. **Softmax分类器**
    **交叉熵损失**
    $$
    L_i=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})
    $$
    在计算时中间项可能数值非常大，通常可在分子分母同乘以常数$$C, logC=-max_jf_j$$，就是将向量$$f$$中的数值进行平移，使得最大值为0
    $$
    \frac{e^{f_{y_i}}}{\sum_je^{f_j}}=\frac{Ce^{f_{y_i}}}{C\sum_je^{f_j}}=\frac{e^{f_{y_i}+logC}}{\sum_je^{f_j}+logC}
    $$

11. 通常来说两种分类器的表现差别很小，相对于Softmax分类器，SVM更加**”局部目标化“**，如第一个分类是正确的，$$[10, -100, -100]​$$或者$$[10, 9, 9]​$$对SVM来说没有不同。

    但对于Softmax分类器，前者的损失值远高于后者，换言之Softmax分类器对于分数是永远不会满意的：**正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小**。但SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。这可以被看做是SVM的一种特性。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。

### Study3

1. 损失函数最优化：随机搜索（随机枚举点，立刻更新权值），随机本地搜索（随机枚举点，损失变小才更新权值），跟随梯度（在梯度负方向更新）

2. 梯度计算：数值梯度法、分析梯度法

   - 数值梯度法：利用有限差值计算梯度
     $$
     grad=\frac{f(x+h)-f(x)}{h}
     $$
     中心差值公式效果更好
     $$
     grad=\frac{f(x+h)-f(x-h)}{2h}
     $$

   - 分析梯度法：利用微分公式求梯度

     在实际操作时为避免出错，常常将分析梯度法的结果与数值梯度法的结果作比较，以此检查实现的准确性

3. 小批量梯度下降：计算训练集中的小批量对权值进行更新

   当每个批量只有1个数据样本时，这种策略被称为随机梯度下降

4. 反向传播：利用链式法则递归计算表达式梯度

   比较难的是向量法操作计算维度，有个技巧是根据维度判断，无须记忆

### Study4

1. 全连接神经元参数爆炸

2. 卷积神经网络

   - 卷积层

     - 滤波器 filter
     - 感受野 receptive field
     - 深度
     - 步长 stride
     - 零填充 zero-padding

     卷积输出尺寸为（$W$为输入数据体尺寸，$F$为感受野尺寸，$P$为零填充数量，$S$为步长）
     $$
     W_2=（W_1-F+2P)/S+1
     $$

     $$
     H_2=（H_1-F+2P)/S+1
     $$
   参数数量为$F*F*D*K+K$，$K为滤波器数量$


     参数共享，深度切片 depth slice

   - 汇聚（Polling）层

     通常采用$2*2$滤波器，取最大值，计算与上述类似（没有零填充）

     未来可能很少甚至不使用汇聚层，可能使用较大的步长的卷积层代替

   - 全连接层

     与卷积层互化

   - ReLU层

3. 常见的卷积网络结构

   ![](./pic/4.jpg)

4. 几个小滤波器卷积层的组合比一个大滤波器卷积层好

5. 层的尺寸设置规律

   ![](./pic/5.jpg)

6. 在实际应用中，更小的步长效果更好。步长为1可以让空间维度的降采样全部由汇聚层负责，卷积层只负责对输入数据体的深度进行变换


### Study5

1. 单个神经元作为线性分类器，在输出端设置何时的损失函数

   设置sigmoid函数得二分类Softmax分类器，设置最大边界折叶损失函数得二分类SVM分类器

   正则化所有权重逐渐向零变化，从生物学角度可以看做逐渐遗忘

2. **常用激活函数**


- **Sigmoid**
  $$
  \sigma (x)=\frac{1}{1+e^{-x}}
  $$
  <img src="./pic/6.jpg" style="zoom:50" />

  - 将输入值压缩到$[0, 1]$，将很大的负数变成0，很大的正数变成1，历史上非常常用，这是因为它对于神经元的激活频率有良好的解释：从完全不激活（0）到在求和后的最大频率处的完全饱和**saturated**的激活（1），现在不常用主要是因为以下**缺点**

  - **Sigmoid函数饱和使梯度消失**。sigmoid神经元有一个不好的特性，就是当神经元的激活在接近0或1处时会饱和：在这些区域，梯度几乎为0。回忆一下，在反向传播的时候，这个（局部）梯度将会与整个损失函数关于该门单元输出的梯度相乘。因此，如果局部梯度非常小，那么相乘的结果也会接近零，这会有效地“杀死”梯度，几乎就有没有信号通过神经元传到权重再到数据了。还有，为了防止饱和，必须对于权重矩阵初始化特别留意。比如，如果初始化权重过大，那么大多数神经元将会饱和，导致网络就几乎不学习了。

  - **Sigmoid函数的输出不是零中心的**。这个性质并不是我们想要的，因为在神经网络后面层中的神经元得到的数据将不是零中心的。这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数（比如在$f=w^Tx+b$中每个元素都$x>0$)，那么关于$w$的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数（具体依整个表达式$f$而定）。这将会导致梯度下降权重更新时出现$Z$字型的下降。然而，可以看到整个批量的数据的梯度被加起来后，对于权重的最终更新将会有不同的正负，这样就从一定程度上减轻了这个问题。因此，该问题相对于上面的神经元饱和问题来说只是个小麻烦，没有那么严重。

    <img src="./pic/7.jpg" style="zoom:50" />

  - 注意理解神经网络是有很多隐藏层的，多个隐藏层都用sigmoid时就会出现隐藏层输出都为正数，在反向传播时就会出现恒正或恒负的情况，就上图的二维梯度下降而言，梯度只能在第一和第三象限的方向减少，收敛极慢


   - **Tanh**
     $$
     tanh(x)=2\sigma (2x)-1
     $$
     <img src="./pic/8.jpg" style="zoom:50" />

     将实数值压缩到$[-1, 1]$中，同样也**存在饱和问题**，但不同的是**输出是零中心的**，因此在实际操作中比sigmoid函数更受欢迎

   - **ReLU**
     $$
     f(x)=max(0, x)
     $$
     <img src="./pic/9.jpg" style="zoom:50" />

     激活函数是一个关于0的阈值

     **优点**是相较于sigmoid和tanh函数，ReLU对于随机梯度的下降的收敛有巨大的加速作用，某论文实验中有6倍之多，据称是由于它的线性、非饱和的公式导致的

     **缺点**是在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低

   - **Leaky ReLU**
     $$
     f(x)=\alpha x,(x<0)，\alpha是一个小的常量\\
     f(x)=x,(x>=0)
     $$
     <img src="./pic/11.jpg" style="zoom:50" />

     除了有ReLU的优点外，还不会死掉

   - **ELU**
     $$
     f(x)=\alpha (e^x-1), (x <= 0)\\
     f(x)=x, (x > 0)
     $$
     ReLU的所有优点，与Leaky ReLU相比负向饱和状态增加了对噪声的鲁棒性，但指数计算量大

   - **Maxout**
     $$
     f(x)=max(w^T_1x+b_1, w^T_2x+b_2)
     $$
     ReLU和Leaky ReLU都是这个公式的特殊情况，拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。

 **一般来说，用ReLU非线性函数，注意设置好学习率**，监控网络中死亡神经元的比率。如果担心单元死亡问题，就试试Leaky ReLU或者Maxout，不要用sigmoid了。也可以试试tanh，但是其效果应该不如ReLU或者Maxout

3. 给出任意连续的函数$f(x)$和任意$\varepsilon > 0$，均存在一个至少含1个隐层的神经网络$g(x)$（并且网络中有合理选择的非线性激活函数，比如sigmoid），对于$\forall x$，使得$|f(x)-g(x)| < \varepsilon$，换句话说**神经网络可以近似任何连续函数**

   虽然一个2层网络在数学理论上能完美地近似所有连续函数，但在实际操作中效果相对较差，虽然在**理论上深层网络（使用了多个隐层）和单层网络的表达能力是一样的**，但是就实践经验而言，深度网络效果比单层网络好。在实践中3层的神经网络会比2层的表现好，然而继续加深（做到4，5，6层）很少有太大帮助。**卷积神经网络的情况却不同**，在卷积神经网络中，对于一个良好的识别系统来说，深度是一个极端重要的因素（比如数十(以10为量级)个可学习的层）。对于该现象的一种解释观点是：因为图像拥有层次化结构（比如脸是由眼睛等组成，眼睛又是由边缘组成），所以多层处理对于这种数据就有直观意义。

4. **用正则化、dropout和输入噪声等来控制过拟合比减少神经元数目要好得多**。不要减少网络神经元数目的主要原因在于**小网络更难使用梯度下降等局部方法来进行训练**：虽然小型网络的损失函数的局部极小值更少，也比较容易收敛到这些局部极小值，但是这些最小值一般都很差，损失值很高。相反，大网络拥有更多的局部极小值，但就实际损失值来看，这些局部极小值表现更好，损失更小

5. PCA：对数据零中心化处理，然后计算协方差矩阵，进行奇异值分解，得到矩阵$U$中为按特征值大小排序的特征向量，取前几项点乘即可降维**（PCA后数据变成零中心）**

6. 白化：归一化处理（没看懂）

7. 实际上在卷积神经网络中并不会采用PCA和白化，然而对数据进行零中心化操作还是非常必要的，对每个像素进行归一化也很常见

8. 预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。**应该怎么做呢？应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值**

9. **权重初始化**

   - **错误的**全零初始化

     如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。换句话说，如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头

   - 小随机数初始化

     权重初始值要非常接近0又不能等于0。解决方法就是将权重初始化为很小的数值，以此来*打破对称性*。其思路是：如果神经元刚开始的时候是随机且不相等的，那么它们将计算出不同的更新，并将自身变成整个网络的不同部分
     $$
     W=0.01*np.random.randn(D, H),\\randn函数是基于零均值和标准差的一个高斯分布
     $$

   - 使用$\frac{1}{sqrt(n)}​$校准方差

     随着输入数据量的增长，随机初始化的神经元的输出数据的分布中的方差也在增大。我们可以除以输入数据量的平方根来调整其数值范围，这样神经元输出的方差就归一化到1了。也就是说，建议将神经元的权重向量初始化为
     $$
     W=0.01*np.random.randn(D, H)/sqrt(n)
     $$

     没看懂证明	

   - 稀疏初始化

     一个处理非标定方差的方法是将所有权重矩阵设为0，但是为了打破对称性，每个神经元都**同下一层固定数目的神经元随机连接**（其权重数值由一个小的高斯分布生成），一个比较典型的连接数目是10个				

   - 偏置初始化

     **通常将偏置初始化为0**，这是因为随机小数值权重矩阵已经打破了对称性。对于ReLU非线性激活函数，有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值，这是因为他们认为这样做能让所有的ReLU单元一开始就激活，这样就能保存并传播一些梯度。然而，这样做是不是总是能提高算法性能并不清楚（有时候实验结果反而显示性能更差），所以通常还是使用0来初始化偏置参数

   实践中使用ReLU函数，并使用$W=np.random.randn(D, H)*sqrt(2.0/n)​$来进行权重初始化

10. **批量归一化**

    [批量归一化](https://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.03167)是loffe和Szegedy最近才提出的方法，该方法减轻了如何合理初始化神经网络这个棘手问题带来的头痛：），其做法是让激活数据在训练开始前通过一个网络，网络处理数据使其服从标准高斯分布。因为归一化是一个简单可求导的操作，所以上述思路是可行的。在实现层面，**应用这个技巧通常意味着全连接层（或者是卷积层，后续会讲）与激活函数之间添加一个BatchNorm层**。对于这个技巧本节不会展开讲，因为上面的参考文献中已经讲得很清楚了，需要知道的是在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。归一化后对轻微扰动不敏感，学习更加容易

11. **梯度下降**

    - 随机梯度下降**SGD**：随机挑选小批量样例对权值进行更新，可能导致Z字形收敛（收敛过慢）、陷入鞍点（导数为0）
      $$
      x_{t+1} = x_t - \alpha \nabla f(x_t)
      $$

      ```python
      while True:
          dx = compute_gradient(x)
          x += learning_rate * dx
      ```

    - **SGD + 动量项momentum**：相当于加速度，沿着原本下降的方向继续前进，越过鞍点，初速度一般初始化为0
      $$
      v_{t+1} = \rho v_t + \nabla f(x_t)\\
      x_{t+1} = x_t - \alpha v_{t+1}
      $$

      $\rho$一般设置为0.9，动量随时间变化的设置有时能略微改善最优化的效果，其中动量在学习过程的后阶段会上升。一个典型的设置是刚开始将动量设为0.5而在后面的多个周期（epoch）中慢慢提升到0.99

      ```python
      vx = 0
      while True:
          dx = compute_gradient(x)
          vx = rho * vx + dx
          x -= learning_rate * vx
      ```

    - **Nesterov Momentum**：在加上加速度的点上取梯度，回到初始点进行更新
      $$
      v_{t+1} = \rho v_t - \alpha \nabla f(x_t + \rho v_t)\\
      x_{t+1} = x_t + v_{t+1}
      $$
      原式子不便于同时计算损失值和梯度，换元如下
      $$
      \widetilde {x_t} = x_t + \rho v_t\\
      v_{t+1} = \rho v_t + \nabla f(\widetilde {x_t})\\
      \widetilde {x_{t+1}} = \widetilde {x_t} - \rho v_t + (1 + \rho) v_{t+1}\\
      = \widetilde {x_t} + v_{t+1} + \rho (v_{t+1} - v_t)
      $$

      ```python
      v = 0
      while True:
          dx = compute_gradient(x)
          old_v = v
          v = rho * v - learning_rate * dx
          x += -rho * old_v + (1 + rho) * v
      ```

    - **AdaGrad**：梯度除以梯度平方和开方项，适当解决了不同方向梯度变化情况不同的问题（步长很好），对凸函数效果很好，但对非凸函数效果并不好，通常不用

      ```python
      grad_squared = 0
      while True:
          dx = compute_gradient(x)
          grad_squared += dx * dx
          x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)
      ```

    - **RMSProp**：AdaGrad的优化，乘以衰减率，可以很好地选择步长，并且避免了后续步长过小无法更新的问题

      decay_rate是一个超参数，常用的值是[0.9,0.99,0.999]

      ```python
      grad_squared = 0
      while True:
          dx = compute_gradient(x)
          grad_squared = decay_rate * grad_squared + (1 - decay_rate) dx * dx
          x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)
      ```

    - **Adam(almost)**：兼顾上述两类算法优点

      ```python
      first_moment = 0
      second_moment = 0
      while True:
          dx = compute_gradient(x)
          first_moment = beta1 * first_moment + (1 - beta1) * dx
          second_moment = beta2 * second_moment + (1 - beta2) * dx * dx
          x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)
      ```

      在第一步时，由于第二动量初始化为0，衰减率非常接近1，那么求出第二动量项将是一个非常小的数，x会得到一个非常大的步长（第一第二动量项并不总会抵消）

    - **Adam(full form)**

      ```python
      first_moment = 0
      second_moment = 0
      for t in range(num_iterations):
          dx = compute_gradient(x)
          first_moment = beta1 * first_moment * (1 - beta1) * dx
          second_moment = beta2 * second_moment + (1 - beta2) * dx * dx
          first_unbias = first_moment / (1 - beta1 ** t)
          second_unbias = second_moment / (1 - beta2 ** t)
          x -= learning_rate * first_moment / (np.sqrt(second_moment) + 1e-7)
      ```

      **默认用来解决任何问题，如下配置对大多模型起始都好**

      ```python
      beta1 = 0.9
      beta2 = 0.999
      learning_rate = 1e-3 or 5e-4
      ```

12. 学习率衰减

    带动量的SGD学习率衰减很常用，但是像Adam的优化算法很少用

    - **step decay**：每几个epoch学习率减半
    - **exponential decay**：$\alpha = \alpha _0e^{-kt}$
    - **1/t decay**：$\alpha = \alpha _0 / (1 + kt)​$

    **学习率衰减是一个二阶超参数，不在模型开始就决定如何衰减，而是先不采用衰减，观察损失函数，判断何处希望衰减**

13. 前面的优化都是一阶逼近，可使用二阶逼近，牛顿法不需要指定学习率，但海森矩阵的逆运算计算量大，可使用拟牛顿法逼近这个逆，**L-BFGS**为二阶逼近，但在神经网络训练者少用

14. **模型集成**：训练多个独立模型，在测试时取平均结果，通常能提升2%

    在实践的时候，有一个总是能提升神经网络几个百分点准确率的办法，就是在训练的时候训练几个独立的模型，然后在测试的时候平均它们预测结果。集成的模型数量增加，算法的结果也单调提升（但提升效果越来越少）。还有模型之间的差异度越大，提升效果可能越好。进行集成有以下几种方法：

    - **同一个模型，不同的初始化**

      使用交叉验证来得到最好的超参数，然后用最好的参数来训练不同初始化条件的模型。这种方法的风险在于多样性只来自于不同的初始化条件

    - **在交叉验证中发现最好的模型**

      使用交叉验证来得到最好的超参数，然后取其中最好的几个（比如10个）模型来进行集成。这样就提高了集成的多样性，但风险在于可能会包含不够理想的模型。在实际操作中，这样操作起来比较简单，在交叉验证后就不需要额外的训练了

    - **一个模型设置多个记录点**

      如果训练非常耗时，那就在不同的训练时间对网络留下记录点（比如每个周期结束），然后用它们来进行模型集成。很显然，这样做多样性不足，但是在实践中效果还是不错的，这种方法的优势是代价比较小

    - **在训练的时候跑参数的平均值**

      和上面一点相关的，还有一个也能得到1-2个百分点的提升的小代价方法，这个方法就是在训练过程中，如果损失值相较于前一次权重出现指数下降时，就在内存中对网络的权重进行一个备份。这样你就对前几次循环中的网络状态进行了平均。你会发现这个“平滑”过的版本的权重总是能得到更少的误差。直观的理解就是目标函数是一个碗状的，你的网络在这个周围跳跃，所以对它们平均一下，就更可能跳到中心去

15. **正则化**

    - **L2正则化**：对每个权重$w​$，向目标函数增加一个$\frac{1}{2}\lambda w^2​$，对于大数值的权重向量进行严厉惩罚，倾向于更加分散的权重向量，使网络更倾向于使用所有输入特征，而不是严重依赖输入特征中某些小部分特征
    - **L1正则化**：对每个权重$w$，向目标函数增加一个$\lambda |w|​$，让权重向量在最优化的过程中变得稀疏（即非常接近0），使用L1正则化的神经元最后使用的是它们最重要的输入数据的稀疏子集，同时对于噪音输入则几乎是不变的了。相较L1正则化，L2正则化中的权重向量大多是分散的小数字。**在实践中，如果不是特别关注某些明确的特征选择，一般说来L2正则化都会比L1正则化效果好**
    - **Elastic net regularization**：将L1正则化和L2正则化组合，$\lambda _1|w| + \lambda _2w^2$
    - **最大范式约束**：给每个神经元中权重向量的量级设定上限，并使用投影梯度下降来确保这一约束，在实践中，与之对应的是参数更新方式不变，然后要求神经元中的权重向量满足$||\vec{w}|||_2<c，c=3或4​$，，即使在学习率设置过高的时候，网络中也不会出现数值“爆炸”

    - **Dropout**：在网络每次前向传播，随机将部分神经元激活函数结果置零，一般取0.5的概率，在全连接层中常见，在卷积层中也会使用，但并不是将神经元激活函数结果置零，而是随机将某几个通道置零（某些特征），需要使用更长时间训练

      **预测测试集时，简单地用dropout的概率乘以输出**

      上述操作不好的性质是必须在测试时对激活数据要按照![p](https://www.zhihu.com/equation?tex=p)进行数值范围调整。既然测试性能如此关键，实际更倾向使用**反向随机失活（inverted dropout）**，它是在训练时就进行数值范围调整，从而让前向传播在测试时保持不变。这样做还有一个好处，无论你决定是否使用随机失活，预测方法的代码可以保持不变，随机失活时还除以概率$p$

    - **Batch normalization**与deopout有类似效果，更常用
    - **Data Augmentation**：垂直、水平翻转，随机裁剪、放缩，色彩变换等等
    - **DropConnect**：随机将某些权重置零

16. 迁移学习

    固定底层参数，修改顶层权值（通常修改最后一层全连接层）

    ![](./pic/13.jpg)

    

17. 对每个样本可能有多个标签的属性分类，有两种损失函数方法

    - 为每个属性创建一个独立的二分类分类器，针对每个分类的二分类器采用如下公式
      $$
      L_i = \sum_j max(0, 1 - y_{ij}f_j)
      $$
      求和是对所有分类$j$，$y_{ij}$的值为1或-1，具体根据第$i$个样本是否被第$j$个属性打标签而定，当该类别被正确预测并展示时，分值向量$f_j$为正，其余情况为负，可以发现，当一个正样本的得分小于+1，或者一个负样本得分大于-1的时候，算法就会累计损失值

    - 对每种属性训练一个独立的逻辑回归分类器，二分类的逻辑回归分类器只有两个分类$(0,1)$，其中对于分类1的概率为
      $$
      P(y=1|x;w,b)=\frac {1}{1+e^{-w^Tx+b}}=\sigma(w^Tx+b)
      $$
      分类0的概率为
      $$
      P(y=0|x;w,b)=1-P(y=1|x;w,b)
      $$
      损失函数最大化为对数似然函数
      $$
      L_i=\sum_j y_{ij}log(\sigma(f_j))+(1-y_{ij})log(1-\sigma(f_j))
      $$
      $\sigma(\cdot)$梯度计算公式为$\frac{\partial L_i}{\partial f_j}=y_{ij}-\sigma (f_j)$

18. **回归问题**：预测实数值

    L2范式计算为$L_i=||f-y_i||^2_2$

    L1范式计算为$L_i=||f-y_i||_1=\sum _j | f_j-y(i)_j|$

    **L2损失比起较为稳定的Softmax损失来，其最优化过程要困难很多。**直观而言，它需要网络具备一个特别的性质，即对于每个输入（和增量）都要输出一个确切的正确值。而在Softmax中就不是这样，每个评分的准确值并不是那么重要：只有当它们量级适当的时候，才有意义。还有，L2损失鲁棒性不好，因为异常值可以导致很大的梯度。所以在**面对一个回归问题时，先考虑将输出变成二值化是否真的不够用**。例如，如果对一个产品的星级进行预测，使用5个独立的分类器来对1-5星进行打分的效果一般比使用一个回归损失要好很多。分类还有一个额外优点，就是能给出关于回归的输出的分布，而不是一个简单的毫无把握的输出值。如果确信分类不适用，那么使用L2损失吧，但是一定要谨慎：L2非常脆弱，在网络中使用随机失活（尤其是在L2损失层的上一层）不是好主意

### Study6

1. **梯度检查**：理论上简单地将解析梯度和数值计算梯度进行比较就可，实际操作却更加复杂且容易出错

   - **使用中心化公式**

     使用有限差值近似来计算数值梯度时，常用公式为
     $$
     \frac{df(x)}{dx}=\frac{f(x+h)-f(x)}{h}
     $$
     其中$h$是一个很小的数字，在实践中近似为1e-5，在实践中使用中心化公式更好
     $$
     \frac{df(x)}{dx}=\frac{f(x+h)-f(x-h)}{2h}
     $$
     泰勒展开可以发现第二个公式的项数少得多，更精确

   - **使用相对误差来比较**
     $$
     \frac{|f'_a-f'_n|}{max(|f'_a|,|f'_n|)}
     $$
     在实践中：

     - 相对误差>1e-2：通常就意味着梯度可能出错
     - 1e-2>相对误差>1e-4：要对这个值感到不舒服才行
     - 1e-4>相对误差：这个值的相对误差对于有不可导点的目标函数是OK的。但如果目标函数中没有kink（使用tanh和softmax），那么相对误差值还是太高
     - 1e-7或者更小：好结果，可以高兴一把了

   - **使用双精度**

     使用单精度浮点数进行梯度检查会导致相对误差很高

   - **目标函数的不可导点（kinks）**

     不可导点可能导致梯度检查不准确，如ReLU函数、SVM损失，**可以使用少量的数据点解决该问题**，减小越过不可导点的几率，梯度检查对2-3个数据点有效，基本上对整个批量数据进行梯度检查也是有效的

   - **谨慎设置步长h**

     在实践中h并不是越小越好，因为当$h$特别小的时候，就可能就会遇到数值精度问题。有时候如果梯度检查无法进行，可以试试将$h$调到1e-4或者1e-6，然后突然梯度检查可能就恢复正常

   - **在操作的特性模式中梯度检查**

     让网络学习（“预热”）一小段时间，**等到损失函数开始下降的之后再进行梯度检查**。在第一次迭代就进行梯度检查的危险就在于，此时可能正处在不正常的边界情况，从而掩盖了梯度没有正确实现的事实

   - **不要让正则化吞没数据**

     通常损失函数是数据损失和正则化损失的和（例如L2对权重的惩罚）。需要注意的危险是正则化损失可能吞没掉数据损失，在这种情况下梯度主要来源于正则化部分（正则化部分的梯度表达式通常简单很多）。这样就会掩盖掉数据损失梯度的不正确实现。因此，推荐**先关掉正则化对数据损失做单独检查，然后对正则化做单独检查**。对于正则化的单独检查可以是修改代码，去掉其中数据损失的部分，也可以提高正则化强度，确认其效果在梯度检查中是无法忽略的，这样不正确的实现就会被观察到了

   - **记得关闭随机失活（dropout）和数据扩张（augmentation）**

     在进行梯度检查时，记得关闭网络中任何不确定的效果的操作，比如随机失活，随机数据扩展等。不然它们会在计算数值梯度的时候导致巨大误差。关闭这些操作不好的一点是无法对它们进行梯度检查（例如随机失活的反向传播实现可能有错误）因此，一个更好的解决方案就是在计算$f(x+h)$和$f(x-h)$前强制增加一个特定的随机种子，在计算解析梯度时也同样如此

   - **检查少量的维度。**在实际中，梯度可以有上百万的参数，在这种情况下只能检查其中一些维度然后假设其他维度是正确的。**注意**确认在所有不同的参数中都抽取一部分来梯度检查。在某些应用中，为了方便，人们将所有的参数放到一个巨大的参数向量中。在这种情况下，例如偏置就可能只占用整个向量中的很小一部分，所以不要随机地从向量中取维度，一定要把这种情况考虑到，确保所有参数都收到了正确的梯度

2. 在进行费时费力的最优化之前，先进行一些合理性检查

   - **寻找特定情况的正确损失值**

     在使用小参数进行初始化时，确保得到的损失值与期望一致。最好先单独检查数据损失（让正则化强度为0），如CIFAR-10的softmax分类器，一般期望初始损失值是2.302，这是因为初始时预计每个类别的概率都为0.1，-ln(0.1)=2.302

   - **对小数据子集过拟合**

     在整个数据集进行训练之前，尝试在一个很小的数据集上进行训练（比如20个数据），然后确保能到达0的损失值。进行这个实验的时候，最好让正则化强度为0，不然它会阻止得到0的损失。除非能通过这一个正常性检查，不然进行整个数据集训练是没有意义的

3. **检查整个学习过程**

   查看输出图表，x轴通常表示周期epochs单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望（一个周期意味着每个样本数据都被观察过了一次）

   - **损失函数**

     <img src="./pic/14.jpg" style="zoom:50" />

   - **训练集和验证集准确率**

     <img src="./pic/15.jpg" style="zoom:50" />

   - **权重更新比例**

     跟踪权重中更新值的数量和全部值的数量之间的比例，比较范式，一个经验性的结论是这个比例应该在1e-3左右。如果更低，说明学习率可能太小，如果更高，说明学习率可能太高

   - **每层的激活数据及梯度分布**

     比如，对于使用tanh的神经元，我们应该看到激活数据的值在整个[-1,1]区间中都有分布。如果看到神经元的输出全部是0，或者全都饱和了往-1和1上跑，那肯定就是有问题了

   - **第一层可视化**

     如果是图像数据，第一层特征可视化会有帮助

     ![](./pic/16.jpg)

     **左图**中的特征充满了噪音，这暗示了网络可能出现了问题：网络没有收敛，学习率设置不恰当，正则化惩罚的权重过低。**右图**的特征不错，平滑，干净而且种类繁多，说明训练过程进行良好

4. **超参数**

   - 随机搜索优于网格搜索

     ![](./pic/17.jpg)

     随机选择比网格化的选择更加有效，而且在实践中也更容易实现，通过随机搜索，而不是网格化的搜索，可以让你更精确地发现那些比较重要的超参数的好数值

   - **对于边界上的最优值要小心**

     这种情况一般发生在你在一个不好的范围内搜索超参数（比如学习率）的时候。比如，假设我们使用**learning_rate = 10 \** uniform(-6,1)**来进行搜索。一旦我们得到一个比较好的值，一定要确认你的值不是出于这个范围的边界上，不然你可能错过更好的其他搜索范围

   - **从粗到细地分阶段搜索**

     在实践中，先进行初略范围（比如10 ** [-6, 1]）搜索，然后根据好的结果出现的地方，缩小范围进行搜索。进行粗搜索的时候，让模型训练一个周期就可以了，因为很多超参数的设定会让模型没法学习，或者突然就爆出很大的损失值。第二个阶段就是对一个更小的范围进行搜索，这时可以让模型运行5个周期，而最后一个阶段就在最终的范围内进行仔细搜索，运行很多次周期

### Study7

1. 深度学习框架

   <img src="./pic/18.jpg" style="zoom:20" />

2. **ImageNet比赛**

   <img src="./pic/20.jpg" style="zoom:10" />池化层无参数

3. **AlexNet**

   <img src="./pic/19.jpg" style="zoom:0" />

   当时GPU无法容纳模型全部参数，分割成两部分在两个GPU处理

   CONV1、CONV2、CONV4、CONV5只与相同GPU上的特征图连接

   COV3、FC6、FC7、FC8连接两个GPU

4. **VGG**

   <img src="./pic/21.jpg" style="zoom:0" />

   使用更小规模过滤器，3个3\*3等同于 7\*7，一个点与周围7\*7个点有关系，总参数数量更少

   VGG19与VGG16类似，多两层卷积层，深度指神经层数

   大部分内存在前面的卷积层，大部分参数在后面的全连接层

   <img src="./pic/22.jpg" style="zoom:0" />

   FC 4096可很好提取图像特征，用于迁移学习

5. **GoogLeNet**

   <img src="./pic/26.jpg" style="zoom:0" />

   无全连接层，仅500万参数

   <img src="./pic/24.jpg" style="zoom:0" />

   保存相同尺寸扩展深度，零填充相同步长卷积，简单级联

   通过1\*1卷积核减少运算次数，可能胡丢失一些信息，但效果很好

   <img src="./pic/25.jpg" style="zoom:0" />

   辅助输出防止梯度弥散

6. **ResNet**

   <img src="./pic/27.jpg" style="zoom:0" />

   不带残差神经网络，深度更深并不能表现更好

   <img src="./pic/28.jpg" style="zoom:0" />

   残差指$F(x)$，是一种直觉和假设

   <img src="./pic/29.jpg" style="zoom:0" />

7. 网络结构比较

   <img src="./pic/30.jpg" style="zoom:0" />

### Study 8

1. VGG和GoogLeNet都是在批量标准化之前提出的，训练需要很多的技巧才能实现收敛，VGG实际上是先训练了11层的模型，再随机加入几层实现了VGG16和VGG19，GoogLeNet中的辅助输出也是为了将额外的梯度直接注入下层

2. 残差路径可以使得梯度直接传播，收敛更好

3. RNN

   <img src="./pic/31.jpg" style="zoom:20" />

   - 一对多：图片文字描述
   - 多对一：文字情感分析/视频行为
   - 多对多：翻译
   - 全对全：视频每帧行为分析

4. Sequence to Sequence: Many to One + One to Many（编码器+解码器）

   <img src="./pic/32.jpg" style="zoom:20" />

5. 字符预测

   <img src="./pic/33.jpg" style="zoom:40" />

   不是单纯选择概率最大的字符，而是按概率选择，这样可以保证生成更多样的字符串

6. 沿时间阶段反向传播

   <img src="./pic/34.jpg" style="zoom:40" />

7. 图片描述

   <img src="./pic/35.jpg" style="zoom:30" />

   注意力机制

   <img src="./pic/36.jpg" style="zoom:30" />

8. LSTM

   <img src="./pic/37.jpg" style="zoom:20" />

   <img src="./pic/38.jpg" style="zoom:20" />

### Study9

1. 其他计算机视觉任务

   <img src="./pic/39.jpg" style="zoom:30" />

2. 语义分割（同一个狗相同，与实例分割区别）

   <img src="./pic/46.jpg" style="zoom:30" />

3. 转置矩阵

   <https://blog.csdn.net/LoseInVain/article/details/81098502>

   上采样的一种方式，转置矩阵的参数不一定从原始的卷积矩阵中简单转置得到，转置这个操作只是提供了转置矩阵的形状而已

   <img src="./pic/40.jpg" style="zoom:30" />

   <img src="./pic/41.jpg" style="zoom:30" />

   <img src="./pic/42.jpg" style="zoom:30" />

   <img src="./pic/45.jpg" style="zoom:30" />

4. 目标定位

   <img src="./pic/47.jpg" style="zoom:30" />

   回归损失：输出连续（L1、L2）

   分类损失：输出离散（SVM、Softmax）

5. 目标检测

   与定位不同的是，不知道对象数量

   - 准确率$\frac{TP}{TP+TN+FP+FN}$

   - 精确率$\frac{TP}{TP+FP}$

   - 召回率$\frac{TP}{TP+FN}$

   先选定候选区域，再进行目标检测

   <img src="./pic/48.jpg" style="zoom:30" />

   计算量大，时间花费大

   Fast ENN和Faster RNN

   <img src="./pic/49.jpg" style="zoom:30" />

   <img src="./pic/50.jpg" style="zoom:30" />

6. 实例分割（不同狗算不同）

   <img src="./pic/51.jpg" style="zoom:30" />

   Mask R-CNN在Faster R-CNN上发展而来，集合了以上所有计算机视觉问题，对每个候选框增加一个独立分支进行训练

### Study10

1. 理解卷积

   <img src="./pic/52.jpg" style="zoom:30" />

2. 有监督学习与无监督学习

   <img src="./pic/53.jpg" style="zoom:30" />

3. 生成模型

   <img src="./pic/54.jpg" style="zoom:30" />

4. PixelRNN与PixelCNN

   <img src="./pic/56.jpg" style="zoom:30" />

   <img src="./pic/55.jpg" style="zoom:30" />

5. VAE

   <img src="./pic/57.jpg" style="zoom:30" />

   <img src="./pic/58.jpg" style="zoom:30" />

6. GAN

   <img src="./pic/59.jpg" style="zoom:30" />

   <img src="./pic/60.jpg" style="zoom:30" />

7. Deep Q-learning

   <img src="./pic/61.jpg" style="zoom:30" />

8. Policy Gradient

   <img src="./pic/62.jpg" style="zoom:30" />

   <img src="./pic/63.jpg" style="zoom:30" />

   <img src="./pic/64.jpg" style="zoom:30" />

9. 对抗样本与对抗训练（待续）





















